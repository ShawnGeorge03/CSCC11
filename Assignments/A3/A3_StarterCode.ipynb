{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_hwFIUlFzTYw",
    "outputId": "9419a67b-5c1d-47e0-a7f5-ec9b9cad5bca"
   },
   "outputs": [],
   "source": [
    "import soundfile, os, glob, librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GWrZdqrp2E98"
   },
   "outputs": [],
   "source": [
    "emotions ={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrgQMSEU-nzZ"
   },
   "source": [
    "### Data for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vSe0sBT12HgO"
   },
   "outputs": [],
   "source": [
    "def load_extract_features(data_path):\n",
    "\n",
    "    '''\n",
    "    load_extract_features() is a function that is used to load all the audio files one at a time, compute their features and return the features as well as the target values.\n",
    "\n",
    "    There are around 8-10 audio files which are corrupted. We hardcode zero values for such files in order to maintain consistency.\n",
    "\n",
    "    ['calm', 'happy'] emotion data is categorized into 'positive' and  ['angry', 'fearful'] into 'negative'\n",
    "\n",
    "    Returns:\n",
    "    1. Features\n",
    "    2. Binary Target Values\n",
    "    '''\n",
    "    final_features,target_emotions, binary_label = [],[], []\n",
    "    count = 0\n",
    "\n",
    "    for i in glob.glob(data_path + \"/Actor_*/*.wav\"): #Loop to read every file.\n",
    "\n",
    "        name = os.path.basename(i)\n",
    "        #We split the name of the file to understand the emotion associated with the file.\n",
    "        split = name.split(\"-\")\n",
    "        #We know that the third identifier is associated with the emotion of the audio file. Hence, we use [2] as it represents the third identifier.\n",
    "        emotion = emotions[split[2]]\n",
    "\n",
    "        #Below is the code to categorize the emotions into two classes to make this a binary problem.\n",
    "        if emotion in ['calm', 'happy']:\n",
    "            binary_label.append(-1)\n",
    "        elif emotion in ['angry', 'fearful']:\n",
    "            binary_label.append(1)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        with soundfile.SoundFile(i) as audio:\n",
    "            waveform = audio.read(dtype=\"float32\")\n",
    "            sr = audio.samplerate\n",
    "\n",
    "            #Below is the code to extract the Mel spectrogram features\n",
    "            #128 is the standard for machine learning applications using Mel spectrograms\n",
    "            m_feature = librosa.feature.melspectrogram(y=waveform, sr=sr, n_mels=128, fmax=sr / 2.0).T\n",
    "            melspectrogram = np.mean(m_feature,axis=0)\n",
    "            if melspectrogram.shape != (128,):\n",
    "                melspectrogram = np.zeros(128)\n",
    "\n",
    "            #Below is the code to extract the chromagram features\n",
    "            stft_wave = librosa.stft(waveform)\n",
    "            stft = np.abs(stft_wave)\n",
    "            c_feature = librosa.feature.chroma_stft(S=stft, sr=sr).T\n",
    "            chromagram = np.mean(c_feature,axis=0)\n",
    "\n",
    "            #12 is the number of pitch classes\n",
    "            if chromagram.shape != (12,):\n",
    "                chromagram = np.zeros(12)\n",
    "\n",
    "            features=np.array([])\n",
    "            features=np.hstack((chromagram, melspectrogram))\n",
    "\n",
    "            final_features.append(features)\n",
    "            target_emotions.append(emotion)\n",
    "\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                print(\"Processed Audio File Number: \", count)\n",
    "\n",
    "    #We return the features and the binary target values.\n",
    "    return np.array(final_features), np.array(binary_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aER6S-_k2a9H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Audio File Number:  100\n",
      "Processed Audio File Number:  200\n",
      "Processed Audio File Number:  300\n",
      "Processed Audio File Number:  400\n",
      "Processed Audio File Number:  500\n",
      "Processed Audio File Number:  600\n",
      "Processed Audio File Number:  700\n"
     ]
    }
   ],
   "source": [
    "#Please change the path below to the path of the folder saved in your computer.\n",
    "data_path = './Audio_Speech_Actors_01-24'\n",
    "X, y = load_extract_features(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.6629422718808193\n",
      "Test Accuracy:  0.6493506493506493\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=2)\n",
    "\n",
    "STEP_SIZE = 0.001\n",
    "\n",
    "def train(X, y, max_iters=1000):\n",
    "    N, N_f = X.shape\n",
    "\n",
    "    w = np.zeros((N_f, ))\n",
    "    b = 0\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        dw = np.zeros((N_f, ))\n",
    "        db = 0\n",
    "\n",
    "        distances = 1 - y * (np.dot(X, w) + b)\n",
    "        distances[distances < 0] = 0\n",
    "\n",
    "        for idx, distance in enumerate(distances):\n",
    "            if distance == 0:\n",
    "                dw += STEP_SIZE * w\n",
    "                db += 0\n",
    "            else:\n",
    "                dw += STEP_SIZE * w - y[idx] * X[idx]\n",
    "                db += -y[idx]\n",
    "\n",
    "        w -= STEP_SIZE/N * dw\n",
    "        b -= STEP_SIZE/N * db\n",
    "\n",
    "\n",
    "    return w, b\n",
    "\n",
    "def predict(X, w, b):\n",
    "    return np.sign(np.dot(X, w) + b)\n",
    "\n",
    "w, b = train(X_train, y_train)\n",
    "\n",
    "y_pred = predict(X_train, w, b)\n",
    "print(\"Train Accuracy: \", accuracy_score(y_train, y_pred))\n",
    "\n",
    "y_pred = predict(X_test, w, b)\n",
    "print(\"Test Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.6610800744878957\n",
      "Test Accuracy:  0.6623376623376623\n"
     ]
    }
   ],
   "source": [
    "def PCA(X, threshold=0.99):\n",
    "    X_meaned = X - np.mean(X, axis = 0)\n",
    "    cov = np.cov(X_meaned, rowvar=False)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "\n",
    "    sort_order = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvalue = eigenvalues[sort_order]\n",
    "    sorted_eigenvectors = eigenvectors[sort_order]\n",
    "\n",
    "    num_components = X_meaned.shape[-1]\n",
    "    for num_feature in range(1, X.shape[-1] + 1):\n",
    "        h = np.sum(sorted_eigenvalue[:num_feature])/np.sum(sorted_eigenvalue)\n",
    "        if h >= threshold:\n",
    "            num_components = num_feature\n",
    "            break\n",
    "\n",
    "    W = sorted_eigenvectors[:,0:num_components]\n",
    "    return np.dot(W.T, X_meaned.T).T\n",
    "\n",
    "X_reduced = PCA(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, train_size=0.7, test_size=0.3, random_state=2)\n",
    "\n",
    "w, b = train(X_train, y_train)\n",
    "\n",
    "y_pred = predict(X_train, w, b)\n",
    "print(\"Train Accuracy: \", accuracy_score(y_train, y_pred))\n",
    "\n",
    "y_pred = predict(X_test, w, b)\n",
    "print(\"Test Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 ('cscc11')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "85bcffb2f92e5d976c05390d637263682ff066627114711b98042e6877e4a14e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
