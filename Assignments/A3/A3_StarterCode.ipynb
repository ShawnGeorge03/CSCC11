{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_hwFIUlFzTYw",
    "outputId": "9419a67b-5c1d-47e0-a7f5-ec9b9cad5bca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import soundfile, os, glob, librosa\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from copy import deepcopy\n",
    "from IPython.display import display_html\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GWrZdqrp2E98"
   },
   "outputs": [],
   "source": [
    "EMOTIONS ={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "\n",
    "LABELS = {\n",
    "  'positive': 1,\n",
    "  'negative': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrgQMSEU-nzZ"
   },
   "source": [
    "### Data for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vSe0sBT12HgO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 Audio Files\n",
      "Processed 200 Audio Files\n",
      "Processed 300 Audio Files\n",
      "Processed 400 Audio Files\n",
      "Processed 500 Audio Files\n",
      "Processed 600 Audio Files\n",
      "Processed 700 Audio Files\n"
     ]
    }
   ],
   "source": [
    "def load_extract_features(data_path):\n",
    "    \"\"\"\n",
    "    Loads all Audio Files, Computes their features and target values.\n",
    "\n",
    "    There are around 8-10 audio files which are corrupted. We hardcode zero values for such files in order to maintain consistency.\n",
    "\n",
    "    ['calm', 'happy'] emotion data is categorized into 'positive' and  ['angry', 'fearful'] into 'negative'\n",
    "\n",
    "    Args:\n",
    "        data_path (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        tuple: Features and Binary Target Values\n",
    "    \"\"\"\n",
    "\n",
    "    final_features, binary_label = [], []\n",
    "    count = 0\n",
    "\n",
    "    for i in glob.glob(data_path + \"/Actor_*/*.wav\"): #Loop to read every file.\n",
    "\n",
    "        name = os.path.basename(i)\n",
    "        # We split the name of the file to understand the emotion associated with the file.\n",
    "        # We know that the third identifier is associated with the emotion of the audio file.\n",
    "        # Hence, we use [2] as it represents the third identifier.\n",
    "        emotion = EMOTIONS[name.split(\"-\")[2]]\n",
    "\n",
    "        #Below is the code to categorize the emotions into two classes to make this a binary problem.\n",
    "        if emotion in ['calm', 'happy']:\n",
    "            binary_label.append(LABELS['positive'])\n",
    "        elif emotion in ['angry', 'fearful']:\n",
    "            binary_label.append(LABELS['negative'])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        with soundfile.SoundFile(i) as audio:\n",
    "            waveform = audio.read(dtype=\"float32\")\n",
    "            sr = audio.samplerate\n",
    "\n",
    "            # Below is the code to extract the Mel spectrogram features\n",
    "            # 128 is the standard for machine learning applications using Mel spectrograms\n",
    "            m_feature = librosa.feature.melspectrogram(y=waveform, sr=sr, n_mels=128, fmax=sr/2.0).T\n",
    "            melspectrogram = np.mean(m_feature,axis=0)\n",
    "            if melspectrogram.shape != (128,): melspectrogram = np.zeros(128)\n",
    "\n",
    "            # Below is the code to extract the chromagram features\n",
    "            stft_wave = librosa.stft(waveform)\n",
    "            stft = np.abs(stft_wave)\n",
    "            c_feature = librosa.feature.chroma_stft(S=stft, sr=sr).T\n",
    "            chromagram = np.mean(c_feature,axis=0)\n",
    "\n",
    "            # 12 is the number of pitch classes\n",
    "            if chromagram.shape != (12,): chromagram = np.zeros(12)\n",
    "\n",
    "            final_features.append(np.array([*chromagram, *melspectrogram]))\n",
    "\n",
    "            count += 1\n",
    "            if count % 100 == 0: print(f\"Processed {count} Audio Files\")\n",
    "\n",
    "    #We return the features and the binary target values.\n",
    "    return np.array(final_features), np.array(binary_label)\n",
    "\n",
    "#Please change the path below to the path of the folder saved in your computer.\n",
    "data_path = './Audio_Speech_Actors_01-24'\n",
    "X, y = load_extract_features(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE = 0.0001  # Learning Rate for the Gradient Descent\n",
    "\n",
    "def train(X, y, max_iters=1000):\n",
    "    \"\"\"\n",
    "    Finds the Support Vector Machine model parameter estimations using Gradient Descent.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray (Shape: (N, k))): A Nxk matrix containing Mel spectrogram and chromagram data.\n",
    "        y (np.ndarray (Shape: (N, ))): A array representing 1 as 'positive' emotion and -1 as 'negative' emotion.\n",
    "        max_iters (int, optional): Number of iterations for the Gradient Descent Algorithm. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        w, b: (np.ndarray (Shape: (k, )), float): Estimated Weights and Bias Term for the model.\n",
    "    \"\"\"\n",
    "\n",
    "    assert X.shape[0] == y.shape[0], f\"Number of inputs and outputs are different. (X: {X.shape[0]}, y: {y.shape[0]})\"\n",
    "    assert np.array_equal(np.unique(y), [-1, 1]), f\"Labels must be either -1 or 1. (labels: {np.unique(y)}\"\n",
    "\n",
    "    N, N_f = X.shape\n",
    "\n",
    "    # Initializes the weights and bias\n",
    "    w, b = np.zeros((N_f, )), 0\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        sw = np.zeros((N_f, ))\n",
    "        sb = 0\n",
    "\n",
    "        # Calculates the max(0, 1 - y * (X @ w + b))\n",
    "        distances = 1 - y * (np.dot(X, w) + b)\n",
    "        distances[distances < 0] = 0\n",
    "\n",
    "        # Sums up the delta for weights and bias gradients\n",
    "        for idx, distance in enumerate(distances):\n",
    "            if distance == 0:\n",
    "                sw += STEP_SIZE * w\n",
    "                sb += 0\n",
    "            else:\n",
    "                sw += STEP_SIZE * w - y[idx] * X[idx]\n",
    "                sb += -y[idx]\n",
    "\n",
    "       # Moves the weights and bias closer to the estimate\n",
    "        w -= STEP_SIZE * sw/N\n",
    "        b -= STEP_SIZE * sb/N\n",
    "\n",
    "    return w, b\n",
    "\n",
    "def predict(X, w, b):\n",
    "    \"\"\"\n",
    "    Returns predictions using estimated weights and bias term for the SVM model.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray (Shape: (N, k))): A Nxk matrix containing Mel spectrogram and chromagram data.\n",
    "        w (ndarray (Shape: (k, ))): Estimated weights term for the SVM model.\n",
    "        b (float): Estimated bias term for the SVM model.\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray (Shape: (N, ))): Array representing 1 as 'positive' emotion and -1 as 'negative' emotion.\n",
    "    \"\"\"\n",
    "\n",
    "    assert X.shape[1] == w.shape[0], f\"Number of inputs and weights are different. (X: {X.shape[1]}, y: {w.shape[0]})\"\n",
    "\n",
    "    return np.asarray(np.sign(np.dot(X, w) + b), dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X, threshold=0.99):\n",
    "    \"\"\"\n",
    "    Runs a PCA on X with a certain threshold\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray (Shape: (N, d))): A Nxd matrix containing Mel spectrogram and chromagram data.\n",
    "        threshold (float, optional): Threshold for Varaince Maximization. Defaults to 0.99.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray (Shape: (N, k)): A Nxk matrix containing the basis eigenvectors where k << d.\n",
    "    \"\"\"\n",
    "\n",
    "    assert 0.01 <= threshold <= 0.99 , f\"threshold should be a percent between [0.01 , 0.99] (threshold: {threshold})\"\n",
    "\n",
    "    N, _ = X.shape\n",
    "    X_meaned = X - np.mean(X, axis=0)\n",
    "    cov = np.cov(X, rowvar=False) * (N-1)/N\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "\n",
    "    sort_order = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvalue = eigenvalues[sort_order]\n",
    "    sorted_eigenvectors = eigenvectors[sort_order]\n",
    "\n",
    "    num_components = X_meaned.shape[-1]\n",
    "    for k in range(1, X.shape[-1] + 1):\n",
    "        h = np.sum(sorted_eigenvalue[:k])/np.sum(sorted_eigenvalue)\n",
    "        if h >= threshold:\n",
    "            num_components = k\n",
    "            break\n",
    "\n",
    "    W = sorted_eigenvectors[:,0:num_components]\n",
    "    return np.dot(W.T, X_meaned.T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(expected: np.ndarray, actual: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    Calculates the accuracy of each label and overall accuracy\n",
    "\n",
    "    Args:\n",
    "\n",
    "        expected (np.ndarray (Shape: (N, ))): Expected Labels\n",
    "        actual (np.ndarray (Shape: (N, ))): Predicted Labels\n",
    "\n",
    "    Returns:\n",
    "        (DataFrame, str): Label Accuracy, Overall Accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    label_accuracies = []\n",
    "\n",
    "    for label, label_num in LABELS.items():\n",
    "        # Filters the actual values based on the expected index for each label\n",
    "        label_accuracy = np.mean(actual[expected == label_num] == label_num)\n",
    "        label_accuracies.append((label, f'{round(label_accuracy * 100, 2)} %' ))\n",
    "\n",
    "    label_acc = DataFrame(label_accuracies, columns=['Label','Accuracy'])\n",
    "    overall_acc = f'{round(np.average(expected == actual) * 100, 2)}'\n",
    "\n",
    "    return label_acc, overall_acc\n",
    "\n",
    "def dataframe_to_html(df: DataFrame, caption: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts the DataFrame to Inline HTML for Jupyter Notebook\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame to convert\n",
    "        caption (str): Short Description about the DataFrame\n",
    "\n",
    "    Returns:\n",
    "        str: Inline HTML for Jupyter Notebook\n",
    "    \"\"\"\n",
    "\n",
    "    return df.style.set_table_attributes(\"style='display:inline;'\") \\\n",
    "\t\t.set_properties(**{'text-align': 'left'}) \\\n",
    "\t\t.set_table_styles([dict(selector = 'th', props=[('text-align', 'left')])]) \\\n",
    "\t\t.set_caption(f'{caption} Accuracy').hide(axis='index')._repr_html_()\n",
    "\n",
    "def create_report(label_acc_train: DataFrame, label_acc_test: DataFrame, \\\n",
    "    overall_acc_train: str, overall_acc_test: str) -> None:\n",
    "    \"\"\"\n",
    "    Creates a Report for Training and Testing Accuracy Comparison\n",
    "\n",
    "    Args:\n",
    "        label_acc_train (DataFrame): Training Label Accuracy in percentage\n",
    "        label_acc_test (DataFrame): Testing Label Accuracy in percentage\n",
    "        overall_acc_train (str): Overall Training Accuracy in percentage\n",
    "        overall_acc_test (str): Overall Testing Accuracy in percentage\n",
    "    \"\"\"\n",
    "\n",
    "    # Converts DataFrames to Inline HTML\n",
    "    train_df_html = dataframe_to_html(label_acc_train, 'Training')\n",
    "    test_df_html = dataframe_to_html(label_acc_test, 'Testing')\n",
    "\n",
    "    # Organizes the Tables and Text\n",
    "    df_html = f\"<center>{train_df_html}{'&nbsp;'*5}{test_df_html}</center>\\n\"\n",
    "    acc_html = f\"<center><p>Training Overall Accuracy: {overall_acc_train} %</p><p>Testing Overall Accuracy: {overall_acc_test} %</p></center>\"\n",
    "\n",
    "    # Renders the raw HTML onto a Jupyter Notebook\n",
    "    display_html(df_html + acc_html, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2a - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><style type=\"text/css\">\n",
       "#T_d6695 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d6695_row0_col0, #T_d6695_row0_col1, #T_d6695_row1_col0, #T_d6695_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d6695\" style='display:inline;'>\n",
       "  <caption>Training Accuracy</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_d6695_level0_col0\" class=\"col_heading level0 col0\" >Label</th>\n",
       "      <th id=\"T_d6695_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_d6695_row0_col0\" class=\"data row0 col0\" >positive</td>\n",
       "      <td id=\"T_d6695_row0_col1\" class=\"data row0 col1\" >73.61 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d6695_row1_col0\" class=\"data row1 col0\" >negative</td>\n",
       "      <td id=\"T_d6695_row1_col1\" class=\"data row1 col1\" >70.15 %</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<style type=\"text/css\">\n",
       "#T_45216 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_45216_row0_col0, #T_45216_row0_col1, #T_45216_row1_col0, #T_45216_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_45216\" style='display:inline;'>\n",
       "  <caption>Testing Accuracy</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_45216_level0_col0\" class=\"col_heading level0 col0\" >Label</th>\n",
       "      <th id=\"T_45216_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_45216_row0_col0\" class=\"data row0 col0\" >positive</td>\n",
       "      <td id=\"T_45216_row0_col1\" class=\"data row0 col1\" >67.83 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_45216_row1_col0\" class=\"data row1 col0\" >negative</td>\n",
       "      <td id=\"T_45216_row1_col1\" class=\"data row1 col1\" >62.93 %</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</center>\n",
       "<center><p>Training Overall Accuracy: 71.88 %</p><p>Testing Overall Accuracy: 65.37 %</p></center>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Potential Kernal Trick\n",
    "# X = np.mod(X, 12) - Based on # of Pitches improves about 1%\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=2)\n",
    "\n",
    "w, b = train(X_train, y_train)\n",
    "\n",
    "y_pred_train = predict(X_train, w, b)\n",
    "y_pred_test = predict(X_test, w, b)\n",
    "\n",
    "label_acc_train, overall_acc_train = get_accuracy(y_train, y_pred_train)\n",
    "label_acc_test, overall_acc_test = get_accuracy(y_test, y_pred_test)\n",
    "\n",
    "create_report(label_acc_train, label_acc_test, overall_acc_train, overall_acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2b - SVM with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital Feature Size of X: 140\n",
      "New Feature Size of X: 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<center><style type=\"text/css\">\n",
       "#T_40df4 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_40df4_row0_col0, #T_40df4_row0_col1, #T_40df4_row1_col0, #T_40df4_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_40df4\" style='display:inline;'>\n",
       "  <caption>Training Accuracy</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_40df4_level0_col0\" class=\"col_heading level0 col0\" >Label</th>\n",
       "      <th id=\"T_40df4_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_40df4_row0_col0\" class=\"data row0 col0\" >positive</td>\n",
       "      <td id=\"T_40df4_row0_col1\" class=\"data row0 col1\" >92.19 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_40df4_row1_col0\" class=\"data row1 col0\" >negative</td>\n",
       "      <td id=\"T_40df4_row1_col1\" class=\"data row1 col1\" >38.06 %</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<style type=\"text/css\">\n",
       "#T_915da th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_915da_row0_col0, #T_915da_row0_col1, #T_915da_row1_col0, #T_915da_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_915da\" style='display:inline;'>\n",
       "  <caption>Testing Accuracy</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_915da_level0_col0\" class=\"col_heading level0 col0\" >Label</th>\n",
       "      <th id=\"T_915da_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_915da_row0_col0\" class=\"data row0 col0\" >positive</td>\n",
       "      <td id=\"T_915da_row0_col1\" class=\"data row0 col1\" >94.78 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_915da_row1_col0\" class=\"data row1 col0\" >negative</td>\n",
       "      <td id=\"T_915da_row1_col1\" class=\"data row1 col1\" >34.48 %</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</center>\n",
       "<center><p>Training Overall Accuracy: 65.18 %</p><p>Testing Overall Accuracy: 64.5 %</p></center>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_reduced = PCA(X)\n",
    "\n",
    "print('Inital Feature Size of X:', X.shape[-1])\n",
    "print('New Feature Size of X:', X_reduced.shape[-1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, train_size=0.7, test_size=0.3, random_state=2)\n",
    "\n",
    "w, b = train(X_train, y_train)\n",
    "\n",
    "y_pred_train = predict(X_train, w, b)\n",
    "y_pred_test = predict(X_test, w, b)\n",
    "\n",
    "label_acc_train, overall_acc_train = get_accuracy(y_train, y_pred_train)\n",
    "label_acc_test, overall_acc_test = get_accuracy(y_test, y_pred_test)\n",
    "\n",
    "create_report(label_acc_train, label_acc_test, overall_acc_train, overall_acc_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 ('cscc11')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "85bcffb2f92e5d976c05390d637263682ff066627114711b98042e6877e4a14e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
