{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvbkHQQkSzdi"
   },
   "source": [
    "# CSCC11 - Introduction to Machine Learning, Fall 2022, Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Shawn Santhoshgeorge (1006094673) \\\n",
    "Anaqi Amir Razif (1005813880)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pK-Wu4hfz97-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import statistics\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e5f5zgrD0DHJ"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "\"\"\"\n",
    "Read the csv file into a DataFrame - df\n",
    "\"\"\"\n",
    "df = pd.read_csv('Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UlYEmMORp1nv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "395         396        324          110                  3  3.5   3.5  9.04   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "397         398        330          116                  4  5.0   4.5  9.45   \n",
       "398         399        312          103                  3  3.5   4.0  8.78   \n",
       "399         400        333          117                  4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "395         1              0.82  \n",
       "396         1              0.84  \n",
       "397         1              0.91  \n",
       "398         0              0.67  \n",
       "399         1              0.95  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Print the DataFrame\n",
    "\"\"\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qG0T29UBp1nw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df:  400\n",
      "Column Names of df:  ['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA', 'Research', 'Chance of Admit ']\n"
     ]
    }
   ],
   "source": [
    "#TO-DO\n",
    "\"\"\"\n",
    "Print the length of the DataFrame.\n",
    "Print the column names of the DataFrame.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Length of df: \", len(df))\n",
    "print(\"Column Names of df: \", list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eI7SRu_kp1nx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (400, 7)\n",
      "Shape of Y:  (400,)\n"
     ]
    }
   ],
   "source": [
    "#TO-DO\n",
    "\"\"\"\n",
    "Define an “X” array that would hold our independent features for regression purposes.\n",
    "Define a \"Y\" array that would hold our target variable.\n",
    "\n",
    "Print the shape of both the arrays.\n",
    "\"\"\"\n",
    "\n",
    "X = df[['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA', 'Research']]\n",
    "Y = df['Chance of Admit ']\n",
    "\n",
    "print(\"Shape of X: \", X.shape)\n",
    "print(\"Shape of Y: \", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5xnt6Wfp1ny"
   },
   "source": [
    "## Split the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JPZ5RlYQp1ny"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "\"\"\"\n",
    "Split the dataset into train dataset and test dataset.\n",
    "Set the random state to any number in order to maintain consistency while generating random numbers over several runs.\n",
    "\"\"\"\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.7, test_size=0.3, random_state=69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eY7EqYsZp1nz"
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hu8lbAnVp1nz"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "def find_optimal_parameters(x, y):\n",
    "    \"\"\" Compute closed form solution for linear regression!\n",
    "    Optimal weight w* in linear regression is given by w* = (X^T X)^(-1) X^T Y\n",
    "\n",
    "    Args:\n",
    "    - x (ndarray (Shape: (N, D))): A NxD matrix corresponding to the inputs.\n",
    "    - y (ndarray (Shape: (N, 1))): A N-column vector corresponding to the outputs given the inputs.\n",
    "\n",
    "    Output:\n",
    "    - w (ndarray (Shape: (D+1, 1))): A (D+1)x1 column vector corresponding to the bias and weights of the linear model.\n",
    "    \"\"\"\n",
    "    # Pad 1's for the bias term, Why? Used for the bias\n",
    "    pad_x = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "\n",
    "    # Note that we could use pseudoinverse here instead: np.linalg.pinv\n",
    "    # @ is alias for matmul\n",
    "    p1 = np.linalg.pinv(np.matrix.transpose(pad_x) @ pad_x) # (X^T X)^(-1)\n",
    "    p2 = np.matrix.transpose(pad_x) @ y # X^T Y\n",
    "    w = p1 @ p2\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hef0J8wPp1nz"
   },
   "source": [
    "### Train linear regression model using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "b2tMQBXYp1n0"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "def get_pred_Y(trained_w, X_pred):\n",
    "    \"\"\" Return predicted Y\n",
    "    Args:\n",
    "    - trained_w (ndarray (Shape: (D+1, 1))): A (D+1)x1 column vector containing linear regression weights.\n",
    "    - X_pred (ndarray (Shape: (N, D))): A NxD matrix corresponding to the prediction inputs.\n",
    "\n",
    "    Output:\n",
    "    - pred_Y (ndarray (Shape: (N, 1))): A Nx1 column vector corresponding to the predicted outputs.\n",
    "    \"\"\"\n",
    "    # Pad 1's for the bias term\n",
    "    pad_x = np.hstack((np.ones((X_pred.shape[0], 1)), X_pred))\n",
    "\n",
    "    pred_Y = pad_x @ trained_w\n",
    "    return pred_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define these metrics and discuss why one would be preferred over the other ?\n",
    "\n",
    "The Mean Absolute Error (MAE) is defined as the following $\\text{MAE} = \\dfrac{\\sum_{i=1}^N |y_i - f(x_i)|}{N}$ and the Mean Squared Error (MSE) is defined as the following $\\text{MSE} = \\dfrac{\\sum_{i=1}^N (y_i - f(x_i))^2}{N}$. The MAE is the average absolute error between the actual and predicted values and the MSE is the average squared error between the actual and predicted values. They both can be used to get an overall performance of the model compared to the dataset but, MSE is preferred over MAE since it helps to point out large errors to a greater extent since it squares the error value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NvJEIbPFp1n0"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "def get_mae(Y_truth, Y_pred):\n",
    "    \"\"\" Return Mean absolute error\n",
    "    Args:\n",
    "    - Y_truth (ndarray (Shape: (N, 1))): A Nx1 column vector corresponding to the actual outputs.\n",
    "    - Y_pred (ndarray (Shape: (N, 1))): A Nx1 column vector corresponding to the predicted outputs.\n",
    "\n",
    "    Output:\n",
    "    - MAE (ndarray (Shape: (1,))).\n",
    "    \"\"\"\n",
    "\n",
    "    'check if both inputs are of the same shape'\n",
    "    assert Y_truth.shape == Y_pred.shape, \"Number of Actual should equal the Number of Predicted Outputs\"\n",
    "\n",
    "    Y_mean = np.absolute(Y_truth - Y_pred)\n",
    "    mae = np.mean(Y_mean)\n",
    "    return mae\n",
    "\n",
    "def get_mse(Y_truth, Y_pred):\n",
    "    \"\"\" Return Mean squared error\n",
    "    Args:\n",
    "    - Y_truth (ndarray (Shape: (N, 1))): A Nx1 column vector corresponding to the actual outputs.\n",
    "    - Y_pred (ndarray (Shape: (N, 1))): A Nx1 column vector corresponding to the predicted outputs.\n",
    "\n",
    "    Output:\n",
    "    - MSE (ndarray (Shape: (1,))).\n",
    "    \"\"\"\n",
    "\n",
    "    'check if both inputs are of the same shape'\n",
    "    assert Y_truth.shape == Y_pred.shape, \"Number of Actual should equal the Number of Predicted Outputs\"\n",
    "\n",
    "    Y_mean = np.square(Y_truth - Y_pred)\n",
    "    mse = np.mean(Y_mean)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihQlEbDzp1n1"
   },
   "source": [
    "### Get predictions on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ycC9grI0rKkn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.13911877  0.00129245  0.00299385  0.00304951  0.00153358  0.01990276\n",
      "  0.12032817  0.03328811]\n"
     ]
    }
   ],
   "source": [
    "w_optimal = find_optimal_parameters(X_train, Y_train)\n",
    "print(w_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jntfL_s7p1n1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error (MSE):  0.004147808502232658\n",
      "Train Error (MAE):  0.045728954899761275\n"
     ]
    }
   ],
   "source": [
    "pred_Y = get_pred_Y(w_optimal, X_train)\n",
    "print('Train Error (MSE): ', get_mse(Y_train.to_numpy(), pred_Y))\n",
    "print('Train Error (MAE): ', get_mae(Y_train.to_numpy(), pred_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrQ5lClCp1n1"
   },
   "source": [
    "### Get predictions and performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Od4gUr8jp1n1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error (MSE):  0.003748193147899049\n",
      "Test Error (MAE):  0.04226151047842842\n"
     ]
    }
   ],
   "source": [
    "pred_Y = get_pred_Y(w_optimal, X_test)\n",
    "print('Test Error (MSE): ', get_mse(Y_test.to_numpy(), pred_Y))\n",
    "print('Test Error (MAE): ', get_mae(Y_test.to_numpy(), pred_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report the corresponding MAE and MSE values\n",
    "\n",
    "The Train Error for MAE and MSE is approximately as follows:\n",
    "\n",
    "| MSE | MAE |\n",
    "|-----|-----|\n",
    "| 0.004147808502232658 | 0.045728954899761275 |\n",
    "\n",
    "The Test Error for MAE and MSE is approximately as follows:\n",
    "\n",
    "| MSE | MAE |\n",
    "|-----|-----|\n",
    "| 0.003748193147899049 | 0.04226151047842842 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsVtfDC12Rh_"
   },
   "source": [
    "## Silouette Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MBUC-6gR2Vh7",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K = 2. The Silhouette Score is: 0.523697003020886\n",
      "For K = 3. The Silhouette Score is: 0.46196799620849327\n",
      "For K = 4. The Silhouette Score is: 0.46609629756368104\n",
      "For K = 5. The Silhouette Score is: 0.4114277091098109\n",
      "For K = 6. The Silhouette Score is: 0.40338552975455844\n",
      "For K = 7. The Silhouette Score is: 0.3847943002802233\n",
      "For K = 8. The Silhouette Score is: 0.3439602276947788\n",
      "For K = 9. The Silhouette Score is: 0.3374920312014737\n",
      "For K = 10. The Silhouette Score is: 0.32371773649768576\n"
     ]
    }
   ],
   "source": [
    "## TO-DO\n",
    "n_silhouette = []\n",
    "\n",
    "kmeans_kwargs= {\n",
    "    \"init\":\"k-means++\",\n",
    "    \"n_init\":30,\n",
    "    \"max_iter\":250,\n",
    "    \"random_state\":2\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "Perform the following steps:\n",
    "\n",
    "1. Loop over the various possible K values you wish to test\n",
    "2. Initialize a K means object.\n",
    "3. Fit the training data on the K means object.\n",
    "4. Use the silhouette score method available from the sklearn metrics.\n",
    "5. Append the score to the silhouetter_coefficients list.\n",
    "6. Display the the silhouette coefficient associated with each value of K.\n",
    "\"\"\"\n",
    "\n",
    "for k in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
    "    cluster_labels = kmeans.fit_predict(X_train, Y_train)\n",
    "    silhouette_avg = silhouette_score(X_train, cluster_labels)\n",
    "    n_silhouette.append(silhouette_avg)\n",
    "    print(f\"For K = {k}. The Silhouette Score is: {silhouette_avg}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For values of K $\\in [\\text{2, 10}]$. Which value would be the most appropriate?\n",
    "\n",
    "From above we can see that the higest value resulting from the Silhouette coefficient analysis is approximately 0.5237 for K = 2. So the most appropriate value would be K = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0H6Djcju85JN"
   },
   "source": [
    "# K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6BvShiJG88NZ"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "# Set the number of clusters based on the silhouette coefficient analysis\n",
    "N_CLUSTERS = 2\n",
    "\n",
    "kmeans = KMeans(\n",
    "    init=\"k-means++\",\n",
    "    n_clusters=N_CLUSTERS , #Input the value you configured using the Silhouette coefficient analysis.\n",
    "    n_init=30,\n",
    "    max_iter=250,\n",
    "    random_state=2\n",
    ")\n",
    "\n",
    "#TO-DO\n",
    "# Fit to the training data\n",
    "kmeans.fit(X_train.to_numpy(), Y_train.to_numpy())\n",
    "\n",
    "#TO-DO\n",
    "# Add the features and the training data you used to the variable below.\n",
    "training_df_clustered = X_train.assign(cluster=kmeans.labels_)\n",
    "\n",
    "#TO-DO\n",
    "# Predict clusters for the training data\n",
    "train_cluster = kmeans.predict(X_train.to_numpy())\n",
    "\n",
    "#TO-DO\n",
    "# Add the target and predicted clusters to the training DataFrame\n",
    "training_df_clustered['cluster'] = train_cluster\n",
    "\n",
    "X_train_clusters_df = []\n",
    "for i in range(N_CLUSTERS):\n",
    "    X_train_clusters_df.append(training_df_clustered[training_df_clustered['cluster']==i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVbD_sYQ88qB"
   },
   "source": [
    "# Building Linear Regression for our clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BMwMKQEpLm2F"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\"\"\"\n",
    "The number of clusters would be defined by the outcome of the silhouetter coefficient\n",
    "Set up the model of Linear Regression by exploring the different parameters: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "train_clusters_df is a dataframe that contains both the true cluster values and the predicted cluster values. Feel free to change the variable name to something else if you have been following a different naming convention.\n",
    "\"\"\"\n",
    "\n",
    "obj_cluster = []\n",
    "\n",
    "for i in range(N_CLUSTERS):\n",
    "    #TO-DO\n",
    "    # Initialize a Linear Regression object.\n",
    "    reg_model = LinearRegression()\n",
    "    #Get the specific X_train values according to their predicted clusters.\n",
    "    X_clustered_data = X_train_clusters_df[i].drop(columns=['cluster'])\n",
    "    #Get the specific Y_train values according to their predicted clusters.\n",
    "    Y_clustered_data = Y_train[X_clustered_data.index]\n",
    "    obj_cluster.append(reg_model.fit(X_clustered_data.to_numpy(), Y_clustered_data.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iOF-lX3dL97-"
   },
   "outputs": [],
   "source": [
    "def predict_value(x_test, kmeans, cluster_linear):\n",
    "  \"\"\"\n",
    "  Input:\n",
    "  x_test is the test value that you wish to predict on.\n",
    "  kmeans is the kmeans object that you have finalized to predict on the test dataset.\n",
    "  cluster_linear is the list of fitted models on different clusters.\n",
    "\n",
    "  Return:\n",
    "  linear_pred - linear_pred will be type list with prediction values\n",
    "  clusters - clusters_pred will be the prediction of clusters using k means.\n",
    "\n",
    "  Follow these steps:\n",
    "  1. Predict clusters using K means object on the test data.\n",
    "  2. Predict regression values using Linear Regression list.\n",
    "  3. return both the predictions.\n",
    "\n",
    "  \"\"\"\n",
    "  clusters = []\n",
    "  linear_pred = []\n",
    "  for index, row in x_test.iterrows():\n",
    "    value = [row]\n",
    "    cluster_label = int(kmeans.predict(value))\n",
    "    chance_to_admit = float(cluster_linear[cluster_label].predict(value))\n",
    "    linear_pred.append(chance_to_admit)\n",
    "  return np.asarray(linear_pred, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-KOf0ncBvkN"
   },
   "source": [
    "# Final Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TAYyCLx8Bcwb"
   },
   "outputs": [],
   "source": [
    "#Apply the clustering-based linear regression to the test set.\n",
    "Y_svr_k_means_pred = predict_value(X_test, kmeans, obj_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7hTtpG7j91JL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error (MSE):  0.003594171024942518\n",
      "Test Error (MAE):  0.04166689615330025\n"
     ]
    }
   ],
   "source": [
    "print('Test Error (MSE): ', get_mse(Y_test.to_numpy(), Y_svr_k_means_pred))\n",
    "print('Test Error (MAE): ', get_mae(Y_test.to_numpy(), Y_svr_k_means_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report the corresponding MAE and MSE values\n",
    "\n",
    "The Test Error for MAE and MSE is as follows:\n",
    "\n",
    "| MSE | MAE |\n",
    "|-----|-----|\n",
    "| 0.003594171024942518 | 0.04166689615330026|\n",
    "\n",
    "In the previous model we assumed that all of the students belongs to one group, but after the Silhouette Coefficient Analysis we noticed that there are 2 clusters. After splitting then using Kmeans++, and then implementing Linear Regression based on the 2 clusters we see that the MSE and MAE have both drastically improved from the previous value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide a brief discussion regarding the factors that might have contributed to this result\n",
    "\n",
    "If we take a look at Cluster 0 and Cluster 1 and compare the Linear Regression Coefficients we can see that some variables are more important than others between them.\n",
    "\n",
    "\n",
    "| Cluster | GRE Score | TOEFL Score | University Rating | SOP | LOR | CGPA | Research |\n",
    "|---------|-----------|-------------|-------------------|-----|-----|------|----------|\n",
    "| 0 | -0.0001575616593894548 | 0.004520914248160211 | 0.008651619805212321 | 0.014163505258192209 | 0.00825716335544579 | 0.10094909980782622 | 0.06810396677370058 |\n",
    "| 1 | 0.001835465193430312 | 0.003454110966154078 | -0.0037986638654450107 | -0.004936007238540335 | 0.027089841781323905 | 0.13311695689261216 | 0.01719038474926861 |\n",
    "\n",
    "\n",
    "As we can see that there are many differences between the Linear Regression Coefficients for each Clusters. \\\n",
    "**Cluster 0:** Favours TOFEL Score, University Rating, SOP, Research \\\n",
    "**Cluster 1:** Favours GRE Score, LOR, CGPA\n",
    "\n",
    "Looking at what each clusters favours we can conclude that what each cluster represents \\\n",
    "**Cluster 0:** Students who have done Research with a Strong Statment of Purpose \\\n",
    "**Cluster 1:** Students who have done well in Academic Courses with Strong Letter of Recommendation"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cscc11')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "85bcffb2f92e5d976c05390d637263682ff066627114711b98042e6877e4a14e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
