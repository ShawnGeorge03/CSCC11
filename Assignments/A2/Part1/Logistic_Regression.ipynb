{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCC11 - Introduction to Machine Learning, Fall 2022, Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Shawn Santhoshgeorge (1006094673) \\\n",
    "Anaqi Amir Razif (1005813880)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Written Component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Width  Height  Orange\n",
      "0      4       4       1\n",
      "1      6       4       1\n",
      "2      6       5       1\n",
      "3      6       8       0\n",
      "4      6      10       0\n",
      "5      8       8       1\n",
      "6      8      10       0\n"
     ]
    }
   ],
   "source": [
    "# Import the Data and Setup X and y for Training\n",
    "df_train = pd.DataFrame({\n",
    "    \"Width\": [4, 6, 6, 6 , 6, 8 , 8],\n",
    "    \"Height\": [4, 4, 5, 8, 10, 8, 10],\n",
    "    \"Orange\": [1, 1, 1, 0, 0, 1, 0]\n",
    "})\n",
    "\n",
    "print(df_train)\n",
    "\n",
    "# Split Data into X and Y\n",
    "X_train = df_train[['Width', 'Height']].to_numpy()\n",
    "y_train = df_train['Orange'].to_numpy()\n",
    "\n",
    "w = np.asarray([0.3,-0.2, 0.7]) # Initial Weights\n",
    "STEP_SIZE = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the corresponding optimization problem in terms of the data provided above and specify the parameters to be estimated\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization problem we are trying to solve is the following\n",
    "\n",
    "Model: $P(\\text{Orange}  | \\mathbf{X}) = \\frac{1}{1 + e^{-\\mathbf{w}^T \\mathbf{X}}}$, where $\\mathbf{w} = \\begin{bmatrix} w_1 \\\\ w_2 \\\\ b \\end{bmatrix}$ and $\\mathbf{X} = \\begin{bmatrix} x_1 \\ (\\text{Weight}) \\\\ x_2 \\ (\\text{Height}) \\\\ 1 \\end{bmatrix}$\n",
    "\n",
    "\n",
    "Given data $\\{x_i, y_i\\}_{i=1, \\cdots, N}$. we minimize the negative log of\n",
    "\n",
    "$\\begin{aligned}\n",
    "p(\\{x_i, y_i\\} | w) &\\propto p(\\{y_i\\} | \\{x_i\\}, w) & \\text{Assume} \\{x_i, y_i\\} \\ \\text{are independent of} \\ w \\\\\n",
    "                    &= \\prod_i^N p(y_i| x_i, w)  & \\text{Assume} \\{x_i, y_i\\} \\ \\text{are independent} \\\\\n",
    "                    &= \\prod_{i:y_i=c_1}^N P(c_1|x_i) \\prod_{i:y_i=c_2}^N (1 - P(c_1|x_i))\n",
    "\\end{aligned}$\n",
    "\n",
    "Let $c_1 = 1 \\ (\\text{Orange})$ and $c_2 = 0 \\ (\\text{Not Orange})$, then the likelihood over $N$ data points can be expressed as\n",
    "\n",
    "$p(\\{x_i, y_i\\} | w) \\propto \\prod_i^N P(c_1|x_i)^{y_i} (1 - P(c_1|x_i))^{(1-y_i)} $\n",
    "\n",
    "To find the estimation for the model parameters we would want to minimize the negative log-likelihood as follows\n",
    "\n",
    "$L(\\mathbf{w}) = - \\sum_{i=1}^N y_i \\text{log}(P(c_1 |x_i)) + (1- y_i) \\text{log}(1 - P(c_2 |x_i))$\n",
    "\n",
    "After taking the derivative of the negative likelihood we get the following $\\frac{\\partial}{\\partial\\mathbf{w}}L(\\mathbf{w}) = -\\sum_{i=1}^N (y_i - p_i)x_i $ where $p_i \\equiv g(w^Tx)$ and $g$ is the sigmoid function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform 3 iterations of the steepest descent algorithm to determine the parameters assuming that the initial estimate is $[0.3,−0.2,0.7]^𝑇$ and the step size (λ) is 0.01. For each estimate (including the initial one), you are required to report the following:\n",
    "    - The value of the estimate\n",
    "    - The accuracy of the resulting logistic regression model when applied to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(values):\n",
    "    \"\"\"\n",
    "    Return the value from the Sigmoid Function\n",
    "\n",
    "    Args:\n",
    "        - values (ndarray (Shape: (N, 1))): Result of the Dot Product with Model Parameters and Input (w^Tx)\n",
    "\n",
    "    Output:\n",
    "        Values from the Sigmoid Function\n",
    "    \"\"\"\n",
    "\n",
    "    'Checks if values is an array'\n",
    "    assert isinstance(values, np.ndarray), 'values must be an ndarray of Nx1'\n",
    "\n",
    "    return 1 / (1 + np.exp(-values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model Parameters:  [ 0.3 -0.2  0.7]\n",
      "Iteration 1: [ 0.20477175 -0.35426438  0.68685387]\n",
      "Iteration 2: [ 0.27913091 -0.3089443   0.69951893]\n",
      "Iteration 3: [ 0.27208574 -0.35574855  0.69978802]\n",
      "\n",
      "After Optimization:  [ 0.27208574 -0.35574855  0.69978802]\n",
      "\n",
      "Train Data Result:  [1 1 1 0 0 1 0]\n",
      "Accuracy on Training Data: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "def train(x, y, init_w, iters=3):\n",
    "    \"\"\"\n",
    "    Finds the model parameter estimations using Gradient Descent\n",
    "\n",
    "    Args:\n",
    "        - x: (ndarray (Shape: (N, 3))): A Nx3 matrix corresponding to the inputs and 1's.\n",
    "        - y: (ndarray (Shape: (N, 1))): A N-column vector corresponding to the outputs given the inputs.\n",
    "        - init_w: (ndarray (Shape: (3, 1))): Initial Weights and Bias Term for the model\n",
    "        - iters (int): Number of iterations for the Gradient Descent Algorithm (Default=3)\n",
    "\n",
    "    Output:\n",
    "        - w: (ndarray (Shape: (3, 1))): Estimated Weights and Bias Term for the model\n",
    "    \"\"\"\n",
    "\n",
    "    # Add Column of 1's for the bias term\n",
    "    X = np.hstack((x, np.ones((x.shape[0], 1))))\n",
    "\n",
    "    # Creates a copy of the initial weights\n",
    "    w = np.copy(init_w)\n",
    "\n",
    "    # Calculates the gradient and moves the weight closer to the estimate\n",
    "    for i in range(iters):\n",
    "        deltaW = np.dot(X.T, (sigmoid(np.dot(X, w)) - y))\n",
    "        w -= STEP_SIZE * deltaW\n",
    "        print(f'Iteration {i + 1}:', w)\n",
    "    return w\n",
    "\n",
    "def predict(x, w) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns predictions for new values\n",
    "\n",
    "    Args:\n",
    "        - x: (ndarray (Shape: (N, 3))): A Nx3 matrix corresponding to the inputs and 1's.\n",
    "        - init_w: (ndarray (Shape: (3, 1))): Estimated Weights and Bias Term for the model\n",
    "\n",
    "    Output:\n",
    "        (ndarray (Shape: (3, 1))): Predictions either 1 or 0\n",
    "    \"\"\"\n",
    "\n",
    "    # Add Column of 1's for the bias term\n",
    "    X = np.hstack((x, np.ones((x.shape[0], 1))))\n",
    "\n",
    "    return 1 * (sigmoid(np.dot(X, w)) >= 1/2)\n",
    "\n",
    "# Model Parameter Optimization\n",
    "print(\"Initial Model Parameters: \", w)\n",
    "w = train(X_train, y_train, w)\n",
    "print(\"\\nAfter Optimization: \", w)\n",
    "\n",
    "# Model Testing on Training Data\n",
    "y_train_pred = predict(X_train, w)\n",
    "print(\"\\nTrain Data Result: \", y_train_pred)\n",
    "print(f\"Accuracy on Training Data: {100 * np.mean(y_train == y_train_pred)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify the following data points using the model you obtained in part b:\n",
    "    - (3,3),  (4, 10), (9, 8), and (9, 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Result:  [1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Import the Data and Setup X for Testing\n",
    "X = np.array([(3,3), (4, 10), (9, 8), (9, 10)])\n",
    "y_pred = predict(X, w)\n",
    "print(\"Test Data Result: \", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the new points fit into the following class\n",
    "\n",
    "<center>\n",
    "\n",
    "| Width \t| Height \t| Orange \t|\n",
    "|-------\t|--------\t|--------\t|\n",
    "| 3     \t| 3      \t| Yes      \t|\n",
    "| 4     \t| 10     \t| No      \t|\n",
    "| 9     \t| 8      \t| Yes      \t|\n",
    "| 9     \t| 10     \t| No      \t|\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss one advantage of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One advantage of Logistic Regression is that it has fewer model\n",
    "parameters compared to another classifier like Gaussian Class\n",
    "Conditionals and Naive Bayes, this means the training phase will be\n",
    "relatively quick to compute and also for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Briefly explain whether Logistic Regression is discriminative or generative ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a discriminative model since it does not attempt\n",
    "to model the complete probability of the training data instead it only\n",
    "attempts to model the conditional probability of the target output given\n",
    "the input, for in this case $P(\\text{Orange} | X)$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cscc11')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85bcffb2f92e5d976c05390d637263682ff066627114711b98042e6877e4a14e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
